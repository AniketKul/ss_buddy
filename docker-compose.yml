version: '3.8'

services:
  study-buddy:
    build: .
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - ROUTER_BASE_URL=http://llm-router:8080
      - NVIDIA_API_KEY=${NVIDIA_API_KEY}
      - SECRET_KEY=${SECRET_KEY:-study-buddy-secret-key}
    volumes:
      - ./logs:/app/logs
    depends_on:
      - llm-router
    restart: unless-stopped

  # Placeholder for NVIDIA LLM Router service
  # In production, this would be replaced with the actual LLM Router deployment
  llm-router:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./mock-router.conf:/etc/nginx/nginx.conf
    restart: unless-stopped

volumes:
  logs: 